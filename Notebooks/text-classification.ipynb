{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import pickle \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# sklear n\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_COLUMS = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "dataset = pd.read_csv('./../data/training.csv', encoding= DATASET_ENCODING, names = DATASET_COLUMS)\n",
    "# Removing the unecessary columns \n",
    "dataset = dataset[['sentiment', 'text']]\n",
    "# replacing the value to ease understanding \n",
    "dataset['sentiment'] = dataset['sentiment'].replace(4,1)\n",
    "# storing the data in lists \n",
    "text ,sentiment = list(dataset['text']), list(dataset['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜€\n",
      "ðŸ˜‰\n",
      "ðŸ¤£\n"
     ]
    }
   ],
   "source": [
    "# grinning face\n",
    "print(\"\\U0001f600\")\n",
    " \n",
    "# grinning squinting face\n",
    "print(\"\\U0001F609\")\n",
    " \n",
    "# rolling on the floor laughing\n",
    "print(\"\\U0001F923\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dictionary containing all emojis with their meaning, \n",
    "emojis = {\n",
    "    ':)':'smile', ':-)':'smile',';d':'wink', ':-E':'vampire',':(':'sad',':-(':'sad', ':-<':'sad',':P':'raspberry',':O':'surprised',\n",
    "    ':-@':'shocked',':@':'shocked',':-$':'confused',':\\\\':'annoyed', ':#':'mute', ':X':'mute', ':^)':'smile', ':-&':'confused','$_$':'greedy',\n",
    "    '@@':'eyeroll',':-!':'confused',':-D':'smile',':-0':'yell','O.o':'confused',\n",
    "    '<(-_-)>':'robot','d[-_-]b':'dj',\":'-)\":'sadsmile',';)':'wink',';-)':'wink','O:-)':'angel', 'O*-)':'angel','(:-D':'gossip', '=^.^=':'cat'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':)': 'smile',\n",
       " ':-)': 'smile',\n",
       " ';d': 'wink',\n",
       " ':-E': 'vampire',\n",
       " ':(': 'sad',\n",
       " ':-(': 'sad',\n",
       " ':-<': 'sad',\n",
       " ':P': 'raspberry',\n",
       " ':O': 'surprised',\n",
       " ':-@': 'shocked',\n",
       " ':@': 'shocked',\n",
       " ':-$': 'confused',\n",
       " ':\\\\': 'annoyed',\n",
       " ':#': 'mute',\n",
       " ':X': 'mute',\n",
       " ':^)': 'smile',\n",
       " ':-&': 'confused',\n",
       " '$_$': 'greedy',\n",
       " '@@': 'eyeroll',\n",
       " ':-!': 'confused',\n",
       " ':-D': 'smile',\n",
       " ':-0': 'yell',\n",
       " 'O.o': 'confused',\n",
       " '<(-_-)>': 'robot',\n",
       " 'd[-_-]b': 'dj',\n",
       " \":'-)\": 'sadsmile',\n",
       " ';)': 'wink',\n",
       " ';-)': 'wink',\n",
       " 'O:-)': 'angel',\n",
       " 'O*-)': 'angel',\n",
       " '(:-D': 'gossip',\n",
       " '=^.^=': 'cat'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading omw-1.4: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# grouping toghther the inflected form ('better.>good)\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(textdata):\n",
    "    processed_texts = []\n",
    "    # Defining regex patterns \n",
    "    url_pattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    user_pattern = '@[^\\s]+'\n",
    "    alpha_pattern = \"[^a-zA-Z0-9]\"\n",
    "    sequence_pattern = r\"(.)\\1\\1+\"\n",
    "    seq_replace_pattern = r\"\\1\\1\"\n",
    "\n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()\n",
    "        # replace all urls with 'url'\n",
    "        tweet = re.sub(url_pattern, 'URL', tweet)\n",
    "        # Replace all emojis \n",
    "        for emoji in emojis.keys():\n",
    "            tweet = tweet.replace(emoji, 'EMOJI'+emojis[emoji])\n",
    "        # replace @username to user \n",
    "        tweet = re.sub(user_pattern, 'USER', tweet)\n",
    "        # replace all non alphabets\n",
    "        tweet = re.sub(alpha_pattern, \" \", tweet)\n",
    "        # replace 3 or more consecutive letters by 2 letter. \n",
    "        tweet = re.sub(sequence_pattern, seq_replace_pattern,tweet)\n",
    "\n",
    "        preprocessed_words = []\n",
    "        for word in tweet.split():\n",
    "            if len(word)>1 and word not in stopwords:\n",
    "                # lemmatize the word \n",
    "                word = lemmatizer.lemmatize(word)\n",
    "                preprocessed_words.append(word)\n",
    "        processed_texts.append(' '.join(preprocessed_words))\n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedtext = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(preprocessedtext, sentiment, test_size= 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=500000, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 459540)\t0.12350740062498185\n",
      "  (0, 457025)\t0.2728345560451567\n",
      "  (0, 456516)\t0.07453853684622454\n",
      "  (0, 404190)\t0.2728345560451567\n",
      "  (0, 403841)\t0.12759108212772935\n",
      "  (0, 396536)\t0.16829060432345327\n",
      "  (0, 387245)\t0.29064040848423905\n",
      "  (0, 387227)\t0.1911713616790475\n",
      "  (0, 385613)\t0.28459480779181556\n",
      "  (0, 385513)\t0.14805801822751993\n",
      "  (0, 328798)\t0.25681828368202336\n",
      "  (0, 327784)\t0.23842042399047453\n",
      "  (0, 265952)\t0.13444360003802303\n",
      "  (0, 228206)\t0.17225108305559025\n",
      "  (0, 223347)\t0.1787780580033966\n",
      "  (0, 161045)\t0.2675532165835685\n",
      "  (0, 159838)\t0.08170817412921148\n",
      "  (0, 121558)\t0.11410796065007721\n",
      "  (0, 57144)\t0.2675532165835685\n",
      "  (0, 57143)\t0.21674145330092714\n",
      "  (0, 20834)\t0.21383153141569364\n",
      "  (0, 8096)\t0.27002841149526857\n",
      "  (0, 8067)\t0.17546550659516488\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    for i in X_train:\n",
    "        print(i)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78    239877\n",
      "           1       0.77      0.80      0.78    240123\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.78      0.78      0.78    480000\n",
      "weighted avg       0.78      0.78      0.78    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BNBModel = BernoulliNB(alpha = 2)\n",
    "BNBModel.fit(X_train, y_train)\n",
    "model_evaluate(BNBModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78    239877\n",
      "           1       0.77      0.80      0.78    240123\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.78      0.78      0.78    480000\n",
      "weighted avg       0.78      0.78      0.78    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVCmodel = LinearSVC()\n",
    "SVCmodel.fit(X_train, y_train)\n",
    "model_evaluate(SVCmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79    239877\n",
      "           1       0.79      0.81      0.80    240123\n",
      "\n",
      "    accuracy                           0.79    480000\n",
      "   macro avg       0.80      0.79      0.79    480000\n",
      "weighted avg       0.80      0.79      0.79    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LRmodel = LogisticRegression(C=2, max_iter = 1000 ,n_jobs = -1)\n",
    "LRmodel.fit(X_train, y_train)\n",
    "model_evaluate(LRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "model_evaluate(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77    399751\n",
      "           1       0.77      0.79      0.78    400249\n",
      "\n",
      "    accuracy                           0.78    800000\n",
      "   macro avg       0.78      0.78      0.78    800000\n",
      "weighted avg       0.78      0.78      0.78    800000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pipeline \n",
    "from sklearn.pipeline import Pipeline \n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessedtext , sentiment, test_size = 0.5, random_state = 0)\n",
    "pipe = Pipeline([('vectorizer',vectorizer), ('bnb', BNBModel)])\n",
    "pipe.fit(X_train, y_train)\n",
    "model_evaluate(pipe)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77    399751\n",
      "           1       0.77      0.79      0.78    400249\n",
      "\n",
      "    accuracy                           0.78    800000\n",
      "   macro avg       0.78      0.78      0.78    800000\n",
      "weighted avg       0.78      0.78      0.78    800000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('pipeline.pickle', 'wb') as f:\n",
    "    pickle.dump(pipe, f)\n",
    "\n",
    "with open('pipeline.pickle', 'rb') as f:\n",
    "    loaded_pipe = pickle.load(f)\n",
    "model_evaluate(loaded_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I hate twitter', 0, 'Negative'), ('May the force be with you.', 1, 'Positive'), (\"Mr. stark, I don't feel so good. \", 1, 'Positive')]\n"
     ]
    }
   ],
   "source": [
    "def predict(model, text):\n",
    "    # predict the sentiment\n",
    "    preprocessed_text = preprocess(text)\n",
    "    predictions = model.predict(preprocessed_text)\n",
    "    pred_to_label = {0:'Negative', 1:'Positive'}\n",
    "    # Make a list of text with sentimet \n",
    "    data = []\n",
    "    for t, pred in zip(text, predictions):\n",
    "        data.append((t, pred, pred_to_label[pred]))\n",
    "    return data \n",
    "if __name__ == \"__main__\":\n",
    "    # Text to classify shold be in a list \n",
    "    text = [\"I hate twitter\", \n",
    "           \"May the force be with you.\",\n",
    "           \"Mr. stark, I don't feel so good. \"]\n",
    "    predictions = predict(loaded_pipe, text)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae490d7ef4e031afb144fbad83122b9dc5e5095f617914afae2b154909a613a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
